---
title: "assigment3w3"
author: "Freddy Simpson"
date: "2023-09-18"
output: word_document
---

```{r}
library(tidyverse)
library(tidymodels)
library(e1071)
library(ROCR)
```
```{r}
library(readr)
parole <- read_csv("~/Desktop/Prescriptive Analitics/Module 2/Weekassignment2/parole.csv")
View(parole)
```
```{r}
str(parole)
summary(parole)
```

```{r}


parole = parole %>% mutate(male= as_factor(male)) %>% 
   mutate(male= fct_recode(male, "female" = "0", "male" = "1" )) 
parole = parole %>% mutate(race = as_factor(race)) %>% 
   mutate(race = fct_recode(race, "White" = "1", "otherwise" = "2" )) 
parole = parole %>% mutate(state = as_factor(state)) %>% 
   mutate(state = fct_recode(state, "Kentucky" = "2", "Louisiana" = "3","Virginia" = "4", "any other state" = "1"  )) 
parole = parole %>% mutate(crime = as_factor(crime)) %>% 
  mutate(crime = fct_recode(crime, "larceny" = "2", "drug-related crime" = "3","driving-related crime" = "4", "any other crime" = "1"  )) 
parole = parole %>% mutate(multiple.offenses= as_factor(multiple.offenses)) %>% 
  mutate(multiple.offenses = fct_recode(multiple.offenses, "incarcerated for multiple offenses" = "1", "otherwise" = "0" )) 
parole = parole %>% mutate(violator = as_factor(violator)) %>% 
  mutate(violator = fct_recode(violator, "arolee violated the parole" = "1", "parolee completed the parole without violation" = "0" )) 

str(parole)
```

```{r}
set.seed(12345)
parole_split = initial_split(parole, prop = 0.70, strata = violator)
paroletrain = training(parole_split)
paroletest = testing(parole_split)
```


```{r}
levels(paroletrain$violator)
```

```{r}
t2 = table(parole$violator, parole$state) #create a table object
prop.table(t2, margin = 2 ) #crosstab with proportions
```


```{r}
parole_model = 
  logistic_reg() %>% #note the use of logistic_reg
  set_engine("glm") #standard logistic regression engine is glm

parole_recipe = recipe(violator ~ state,paroletrain) %>%
  step_dummy(all_nominal(), -all_outcomes()) #exclude the response variable from being dummy converted  

logreg_wf = workflow() %>%
  add_recipe(parole_recipe) %>% 
  add_model(parole_model)

parole_fit = fit(logreg_wf, paroletrain)
```

```{r}
summary(parole_fit$fit$fit$fit)
```

```{r}
paroletrain_model = 
  logistic_reg() %>% #note the use of logistic_reg
  set_engine("glm") #standard logistic regression engine is glm

paroletrain_recipe = recipe(violator ~ state + multiple.offenses + race, paroletrain) %>%
  step_dummy(all_nominal(), -all_outcomes()) #exclude the response variable from being dummy converted  

logreg_wf = workflow() %>%
  add_recipe(paroletrain_recipe) %>% 
  add_model(paroletrain_model)

paroletrain_fit = fit(logreg_wf, paroletrain)
```

```{r}
summary(paroletrain_fit$fit$fit$fit)
```

```{r}
newdata = data.frame(state = "Louisiana", race = "White", multiple.offenses = "incarcerated for multiple offenses" )
predictions= predict( paroletrain_fit, newdata, type="prob")
head(predictions)
```
Develop predictions  
```{r}
predictions = predict(paroletrain_fit, paroletrain, type="prob") #develop predicted probabilities
head(predictions)
```
Let's extract just the "Yes" prediction.  
```{r}
predictions = predict(paroletrain_fit, paroletrain, type="prob")[2]
head(predictions)
```



Threshold selection  
```{r}
#Change this next line to the names of your predictions and the response variable in the training data frame
ROCRpred = prediction (predictions, paroletrain$violator) 

###You shouldn't need to ever change the next two lines:
ROCRperf = performance(ROCRpred, "tpr", "fpr")
plot(ROCRperf, colorize=TRUE, print.cutoffs.at=seq(0,1,by=0.1), text.adj=c(-0.2,1.7))
```

Area under the curve (AUC). AUC is a measure of the strength of the model. Values closer to 1 are better. Can be used to compare models.  
```{r}
as.numeric(performance(ROCRpred, "auc")@y.values)
```

```{r}
#Determine threshold to balance sensitivity and specificity
#DO NOT modify this code
opt.cut = function(perf, pred){
    cut.ind = mapply(FUN=function(x, y, p){
        d = (x - 0)^2 + (y-1)^2
        ind = which(d == min(d))
        c(sensitivity = y[[ind]], specificity = 1-x[[ind]], 
            cutoff = p[[ind]])
    }, perf@x.values, perf@y.values, pred@cutoffs)
}
print(opt.cut(ROCRperf, ROCRpred))
```
Test thresholds to evaluate accuracy  
```{r}
#confusion matrix
#The "No" and "Yes" represent the actual values
#The "FALSE" and "TRUE" represent our predicted values
t1 = table(paroletrain$violator,predictions > 0.2015788)
t1
```

Calculate accuracy  
```{r}
(t1[1,1]+t1[2,2])/nrow(paroletrain)


```
```{r}

```



Sensitivity
```{r}
36/(18+36)
```


```{r}
t3 = table(paroletrain$violator,predictions > 0.2)
t3
(t3[1,1]+t3[2,2])/nrow(paroletrain)
```

```{r}
t4 = table(paroletrain$violator,predictions > 0.3)
t4
(t4[1,1]+t4[2,2])/nrow(paroletrain)
```
```{r}
t5 = table(paroletrain$violator,predictions > 0.4)
t5
(t5[1,1]+t5[2,2])/nrow(paroletrain)
```


```{r}
t6 = table(paroletrain$violator,predictions > 0.5)
t6
(t6[1,1]+t6[2,2])/nrow(paroletrain)
```

```{r}
predictions2 = predict(paroletrain_fit, paroletest, type="prob") #develop predicted probabilities
head(predictions2)
```



```{r}
predictions2 = predict(paroletrain_fit, paroletest, type="prob")[2]
head(predictions2)
```
Threshold selection  
```{r}
#Change this next line to the names of your predictions and the response variable in the training data frame
ROCRpred2 = prediction (predictions2, paroletest$violator) 

###You shouldn't need to ever change the next two lines:
ROCRperf = performance(ROCRpred, "tpr", "fpr")
plot(ROCRperf, colorize=TRUE, print.cutoffs.at=seq(0,1,by=0.1), text.adj=c(-0.2,1.7))
```


Area under the curve (AUC). AUC is a measure of the strength of the model. Values closer to 1 are better. Can be used to compare models.  
```{r}
as.numeric(performance(ROCRpred2, "auc")@y.values)
```


```{r}
#Determine threshold to balance sensitivity and specificity
#DO NOT modify this code
opt.cut = function(perf, pred){
    cut.ind = mapply(FUN=function(x, y, p){
        d = (x - 0)^2 + (y-1)^2
        ind = which(d == min(d))
        c(sensitivity = y[[ind]], specificity = 1-x[[ind]], 
            cutoff = p[[ind]])
    }, perf@x.values, perf@y.values, pred@cutoffs)
}
print(opt.cut(ROCRperf, ROCRpred))
```
```{r}
t7= table(paroletest$violator,predictions2 > 0.5)
t7
(t7[1,1]+t7[2,2])/nrow(paroletest)
```
